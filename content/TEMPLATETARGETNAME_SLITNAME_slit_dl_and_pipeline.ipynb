{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7820f61d-1e48-4281-a934-883580e6b164",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "DL_PATH_NAME = 'mastDownload/flat/'\n",
    "SLIT_NAME = 's00066'\n",
    "PROPOSAL_ID = 2609\n",
    "REDUX_BASE_NAME = 'miscdata/jwst_outputs/'\n",
    "TARGET_NAME = 'NGC6791-NEWCATALOG-GAIAEDR3' # If None, matches against the whole program\n",
    "CONTENT_DIR = '/containerapp/content'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0ba1dc2-c9ae-4fb2-a3dc-6dcac3e85ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "from copy import deepcopy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from astroquery.mast import Observations\n",
    "\n",
    "from astropy.io import fits\n",
    "from astropy import table\n",
    "\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline import Spec2Pipeline\n",
    "\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a49314-f63a-4b94-a745-5766138249c7",
   "metadata": {},
   "source": [
    "The below `chdir` command makes it so that all paths are relative to the content directory, regardless of where this particular notebook is"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db37a0dd-88d0-40eb-bb7d-d1d6b2cb89b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(CONTENT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1c8682-a2b5-44eb-afcf-f4004ad309d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dl_root = Path(f'{DL_PATH_NAME}')\n",
    "flat_dl_root.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac752d56-f863-442e-9496-9a6b672ed74f",
   "metadata": {},
   "source": [
    "The `login` below might succeed even if a token is invalid - it just means you wont have proprietary access. But you will see a warning in the cell output if this happens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0582d001-fa24-475b-83e9-8b539906e015",
   "metadata": {},
   "outputs": [],
   "source": [
    "Observations.login(os.environ['MAST_TOKEN'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501a12b4-609f-4d08-afa9-6d47a027b683",
   "metadata": {},
   "source": [
    "# Download all the necessary files for the particular target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0aabaa-1b65-42db-9204-a073805a3391",
   "metadata": {},
   "outputs": [],
   "source": [
    "obses_table_path = flat_dl_root / f'obses{PROPOSAL_ID}.ecsv'\n",
    "if not obses_table_path.exists():\n",
    "    obses = Observations.query_criteria(proposal_id=PROPOSAL_ID)\n",
    "    obses.write(obses_table_path, format='ascii.ecsv')\n",
    "obses = table.Table.read(obses_table_path, format='ascii.ecsv')\n",
    "\n",
    "obses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b1f2b-5029-4d31-8792-4605008b35c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "specs3 = obses[(obses['calib_level']==3) & (obses['dataproduct_type'] != 'image')]\n",
    "\n",
    "msk = []\n",
    "for row in specs3:\n",
    "    m = re.match('jw.*_(s.*?)_.*', row['obs_id'])\n",
    "    match = m and m.group(1) == SLIT_NAME\n",
    "    if TARGET_NAME is not None:\n",
    "        match = match and (row['target_name']==TARGET_NAME)\n",
    "    msk.append(match)\n",
    "    \n",
    "spec_tab = specs3[np.array(msk)]\n",
    "\n",
    "spec_tab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95955457-3ee1-4d5e-81d5-b5e5e45f0017",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_prods = Observations.get_product_list(spec_tab)\n",
    "spec_prods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f8c79-6ba6-431b-bd2b-38160bf1e483",
   "metadata": {},
   "source": [
    "The below cell is purely informational, it doesn't actually need to be present to run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23e67f2f-2613-4e9d-8ca4-21af5e89ac97",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec3_asn_prod = spec_prods[(spec_prods['productSubGroupDescription']=='ASN') & (spec_prods['type']=='D')]\n",
    "assert len(spec3_asn_prod) == 1\n",
    "\n",
    "spec3_asn_path = flat_dl_root / spec3_asn_prod['productFilename'][0]\n",
    "dl_result = Observations.download_file(spec3_asn_prod['dataURI'][0], local_path=spec3_asn_path)\n",
    "\n",
    "with spec3_asn_path.open() as f:\n",
    "    spec3_asn = json.load(f)\n",
    "spec3_asn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "985cfbaa-c625-4a28-bcf7-57dd488b1b62",
   "metadata": {},
   "outputs": [],
   "source": [
    "spec2_asn_prods = spec_prods[(spec_prods['productSubGroupDescription']=='ASN') & (np.char.find(spec_prods['productFilename'], 'spec2')!=-1)]\n",
    "\n",
    "spec2_asns = {}\n",
    "for prod in spec2_asn_prods:\n",
    "    spec2_asn_path = flat_dl_root / prod['productFilename']\n",
    "    Observations.download_file(prod['dataURI'], local_path=spec2_asn_path)\n",
    "\n",
    "    spec2_asns[prod['productFilename']] = json.load(spec2_asn_path.open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e4db03-3f6b-424e-81dd-106a336168f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "to_dl_fns = []\n",
    "for asn in spec2_asns.values():\n",
    "    assert len(asn['products']) == 1\n",
    "    for memb in asn['products'][0]['members']:\n",
    "        if memb['exptype'] in ('science', 'background'):\n",
    "            to_dl_fns.append(memb['expname'])\n",
    "to_dl_fns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5da0d67-48c0-418a-8409-1e264a92abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn_to_uri = {}\n",
    "for fn in to_dl_fns:\n",
    "    matches = spec_prods[spec_prods['productFilename'] == fn]\n",
    "    assert len(matches)>0,f\"no files found with name {fn}!  This shouldn't happen, freaking out\"\n",
    "    assert len(np.unique(matches['dataURI'])) == 1, \"two different dataURIs match!  This shouldn't happen, freaking out\"\n",
    "    fn_to_uri[fn] = matches[0]['dataURI']\n",
    "    \n",
    "fn_to_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd21dcf-171c-4563-a1f3-bf6896480f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=spec2_input_download\n",
    "\n",
    "input_paths = []\n",
    "for nm, uri in fn_to_uri.items():\n",
    "    res = Observations.download_file(uri, local_path=flat_dl_root / nm)\n",
    "    if res[0] == 'COMPLETE':\n",
    "        input_paths.append(flat_dl_root / nm)\n",
    "    else:\n",
    "        input_paths.append(None)\n",
    "        \n",
    "assert all([pth is not None for pth in input_paths])\n",
    "\n",
    "input_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7073cad0-e8fb-45d2-a1ff-3c62664ef795",
   "metadata": {},
   "source": [
    "This might be overkill, but just assume we need all of the MSAs in the matched product set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcae501-5355-442c-be8a-f37ddeccdb3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#papermill_description=MSA_download\n",
    "\n",
    "for row in spec_prods[spec_prods['productSubGroupDescription']=='MSA']:\n",
    "    Observations.download_file(row['dataURI'], local_path=flat_dl_root / row['productFilename'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc140b08-251b-47ad-85eb-7533afd8487f",
   "metadata": {},
   "source": [
    "# Set up the pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221fa739-bcb2-42cb-929a-9c657d750124",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ.setdefault('CRDS_PATH', '/containerapp/crds_cache')\n",
    "os.environ['CRDS_SERVER_URL'] = 'https://jwst-crds.stsci.edu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ac9ddb-6dba-44c6-ba24-9213acfaf9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "redux_base = Path(REDUX_BASE_NAME) \n",
    "redux_path = redux_base / f'redux_{SLIT_NAME}'\n",
    "\n",
    "redux_path.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97b2184-3a5f-43c4-96cb-2bf706107104",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_paths(asn_fn):\n",
    "    asn = spec2_asns[asn_fn]\n",
    "    \n",
    "    asn = deepcopy(asn)  # this is not necessary if we are not modifying, but is safe just in case\n",
    "    assert len(asn['products']) == 1\n",
    "    \n",
    "    msas = []\n",
    "    prod = asn['products'][0]\n",
    "    for member in prod['members']:\n",
    "        link = redux_path / member['expname']\n",
    "        target = flat_dl_root / member['expname']\n",
    "        if not link.is_symlink():\n",
    "            link.symlink_to(target.resolve())\n",
    "        msas.append(fits.getheader(link).get('MSAMETFL', None))\n",
    "    \n",
    "    for msa in msas:\n",
    "        if msa is not None:\n",
    "            link = redux_path / msa\n",
    "            target = flat_dl_root / msa\n",
    "            if not link.is_symlink():\n",
    "                link.symlink_to(target.resolve())\n",
    "                \n",
    "    with (redux_path / asn_fn).open('w') as f:\n",
    "        json.dump(asn, f)\n",
    "\n",
    "def setup_spec2d():\n",
    "    spec2 = Spec2Pipeline()\n",
    "    spec2.save_results = True\n",
    "    spec2.output_dir = str(redux_path)\n",
    "    \n",
    "    spec2.srctype.source_type = 'POINT'\n",
    "    spec2.flat_field.save_interpolated_flat = True\n",
    "    \n",
    "    spec2.bkg_subtract.skip = False\n",
    "    spec2.resample_spec.skip = True\n",
    "    spec2.extract_1d.skip = True\n",
    "    \n",
    "    spec2.assign_wcs.slit_y_high *= 2\n",
    "    spec2.assign_wcs.slit_y_low *= 2\n",
    "    \n",
    "    return spec2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b568581-b980-4a66-888d-e62d34bdee1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for asn_fn in spec2_asns:\n",
    "    setup_paths(asn_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87d667-b5a6-4d79-bf6b-836bc27d28df",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#papermill_description=Running_spec2\n",
    "\n",
    "outputs = []\n",
    "dts = []\n",
    "for asn_fn, asn in spec2_asns.items():\n",
    "    print(f'\\n\\n\\nSTARTING redux for {asn_fn}')\n",
    "    dts.append((asn_fn, datetime.datetime.utcnow()))\n",
    "\n",
    "    assert len(asn['products']) == 1\n",
    "    expected_outputs = [asn['products'][0]['name'] + '_cal.fits', \n",
    "                        asn['products'][0]['name'] + '_interpolatedflat.fits']\n",
    "\n",
    "    if all((redux_base / outname).exists() for outname in expected_outputs):\n",
    "        print(\"Ouputs\", expected_outputs, 'already exist, symlinking')\n",
    "        for outname in expected_outputs:\n",
    "            output = redux_path / outname\n",
    "            target = redux_base / outname\n",
    "            if output.is_file():\n",
    "                print(output, 'already exists, not symlinking')\n",
    "                outputs.append((output, 'real'))\n",
    "            else:\n",
    "                output.symlink_to(os.path.relpath(target, output.parent))\n",
    "                outputs.append((output, 'symlink'))\n",
    "                \n",
    "    else:\n",
    "        # we do this step to \"reserve\" the outputs, because otherwise another process might try to create it while we are waiting for this one to finish\n",
    "        for outname in expected_outputs:\n",
    "            target = redux_base / outname\n",
    "            with target.open('w') as f:\n",
    "                f.write('placeholder')\n",
    "            \n",
    "        spec2 = setup_spec2d()\n",
    "        result = spec2(redux_path / asn_fn)\n",
    "\n",
    "        for outname in expected_outputs:\n",
    "            output = redux_path / outname\n",
    "            target = redux_base / outname\n",
    "            \n",
    "            if not output.is_file():\n",
    "                raise IOError(f'Output {output} is missing! this is highly irregular...')\n",
    "                \n",
    "            if target.exists():\n",
    "                # critical because the \"reserved\" outputs need to be removed\n",
    "                target.unlink()\n",
    "            target.symlink_to(output.relative_to(target.parent))\n",
    "\n",
    "            outputs.append((output, 'real'))\n",
    "\n",
    "dts.append(('Done', datetime.datetime.utcnow()))\n",
    "with open(redux_path / 'completed_pipeline_run', 'w') as f:\n",
    "    for label, dt in dts:\n",
    "        dtstr = dt.strftime('%Y_%m_%dZ%H_%M_%S')\n",
    "        f.write(f'{label},{dtstr}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fe8c1-0012-490c-b242-eff3b4e729f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for o in outputs:\n",
    "    print(o)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
