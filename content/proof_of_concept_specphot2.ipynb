{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9df65b-097d-4519-8654-c895923a05e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fbdc1e-f6ea-4769-9fbc-b0126681651f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1643db6-b4ee-4320-9a10-f0d9baf827e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls *pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b932b56-48f2-40fa-8909-7f336d46324d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('specphot_phoenix.pickle', 'rb') as f:\n",
    "    dct = pickle.load(f)\n",
    "dct.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4b005f-26f5-4a53-bd5d-059146ec0c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in dct.items():\n",
    "    globals()[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3ef514-45e0-46b2-85ec-bc7d932820d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "absmags.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a1bbd62-9576-4e1d-afaa-8505ad2e9809",
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresl = features.copy()\n",
    "featuresl['logteff'] = np.log10(featuresl.pop('teff'))\n",
    "featuresl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df41dfe-250f-4fb0-a38f-356a62bb4b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "next(iter(featuresl.values())).shape, next(iter(absmags.values())).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a672f17-a32b-4c53-8761-ce667b1ae1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_absmags = {k:v for k,v in absmags.items() if ('F814W' in k or 'F606W' in k)}\n",
    "test_absmags.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f10cfd-4b46-4601-8959-c0ed01e806eb",
   "metadata": {},
   "source": [
    "# SVMs? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e979cb5f-d389-4f0e-accb-693b60642022",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19518163-89ed-402c-af1a-d8ac87d57899",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(list(test_absmags.values()))\n",
    "y = featuresl['logg']\n",
    "\n",
    "plt.scatter(X[0], X[1], c=y, s= 2, alpha=.5)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e89e442-ca87-4206-8d1c-3d2efbacf345",
   "metadata": {},
   "outputs": [],
   "source": [
    "regr = svm.SVR()\n",
    "regr.fit(X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d41e3-32e9-4257-9a27-f774f679b926",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[0], X[1], c=regr.predict(X.T), s= 2, alpha=.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5e351b-8cdc-436a-83cf-c61923e41177",
   "metadata": {},
   "source": [
    "Hmm.  Simple enough it might work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc99085-bbb1-4eab-80f1-aaab2b851a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "svms = {}\n",
    "\n",
    "# this is the default, and it doesn't seem to do much better even trying the others...\n",
    "kernel = 'rbf' # 'linear', 'poly', 'rbf', 'sigmoid'\n",
    "degree = 3\n",
    "\n",
    "for fnm, y in featuresl.items():\n",
    "    svms[fnm] = regr = svm.SVR(kernel=kernel, degree=degree)\n",
    "    regr.fit(X.T, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6725573f-1b01-4b99-818e-1458ce424862",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(svms), 3, figsize=(15, 15))\n",
    "\n",
    "for (ax1, ax2, ax3), (fnm, regr) in zip(axs, svms.items()):\n",
    "    y = featuresl[fnm]\n",
    "    yp = regr.predict(X.T)\n",
    "\n",
    "    mi = np.min(np.concatenate([y, yp]))\n",
    "    mx = np.max(np.concatenate([y, yp]))\n",
    "\n",
    "    sc1 = ax1.scatter(X[0], X[1], c=y, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    sc2 = ax2.scatter(X[0], X[1], c=yp, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    plt.colorbar(sc1).set_label(fnm)\n",
    "\n",
    "    sc3 = ax3.scatter(X[0], y-yp, c=X[1], s=2, alpha=.5)\n",
    "    plt.colorbar(sc3).set_label('mag2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "896a226f-4948-4dd4-b071-1651352e3609",
   "metadata": {},
   "source": [
    "With any choice of kernel we still have this (unsurprising) problem that the Fe/H dependence is hard to capture."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b7c555b-4083-4e6f-b8b9-ed22c42145d3",
   "metadata": {},
   "source": [
    "## Gaussian Process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24fe09a0-744b-49ca-a6d1-e22e2d53fdd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import *\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X = np.array(list(test_absmags.values()))\n",
    "y = featuresl['logg']\n",
    "\n",
    "\n",
    "kernel = 1.0 * ExpSineSquared(1.0, 5.0, periodicity_bounds=(1e-2, 1e1))\n",
    "kernel = 1 * RBF(length_scale=.1, length_scale_bounds=(1e-2, 1e2))\n",
    "kernel = 1 * Matern(length_scale=.1, nu=1.5)\n",
    "\n",
    "gaussian_process = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=9)\n",
    "\n",
    "pl = make_pipeline(StandardScaler(), gaussian_process)\n",
    "pl = gaussian_process\n",
    "\n",
    "sub = np.random.permutation(y.size)[:100]\n",
    "pl.fit(X.T[sub], y[sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a798d9-f6d1-495e-adee-703070edfe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = pl.predict(X.T)\n",
    "\n",
    "mi = np.min(np.concatenate([y, yp]))\n",
    "mx = np.max(np.concatenate([y, yp]))\n",
    "\n",
    "plt.scatter(X[0], X[1], c=y, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "plt.figure()\n",
    "plt.scatter(X[0], X[1], c=yp, s=2, alpha=.5, vmin=mi, vmax=mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a89d1ee6-f191-4dd8-ae4e-1aab458c81f7",
   "metadata": {},
   "source": [
    "Hmm, it works but doesn't converge sometimes?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c1fc2f-dc67-418d-aba2-f3330f9b048a",
   "metadata": {},
   "source": [
    "## Decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5105da4-35ed-45d4-a2c7-48682fb12622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree\n",
    "\n",
    "\n",
    "X = np.array(list(test_absmags.values()))\n",
    "y = featuresl['logg']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cab93a8-5b31-43cb-ad06-9ca2cd579843",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree = tree.DecisionTreeRegressor(max_depth=None)\n",
    "\n",
    "\n",
    "training_sub = np.random.permutation(y.size)[:100000]\n",
    "\n",
    "dtree.fit(X.T[training_sub], y[training_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f72491-77fc-4598-aa0e-99dd3c30040c",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = dtree.predict(X.T)\n",
    "\n",
    "mi = np.min(np.concatenate([y, yp]))\n",
    "mx = np.max(np.concatenate([y, yp]))\n",
    "\n",
    "plt.scatter(X[0], X[1], c=y, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "plt.figure()\n",
    "plt.scatter(X[0], X[1], c=yp, s=2, alpha=.5, vmin=mi, vmax=mx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd29ff5a-961b-43e9-9854-f28558e42984",
   "metadata": {},
   "source": [
    "multioutput?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7edf7d9-387d-413e-9780-38453a8c0deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "yall = np.array(list(featuresl.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2762baf3-859f-4300-abcf-36143b97b065",
   "metadata": {},
   "outputs": [],
   "source": [
    "mtree = tree.DecisionTreeRegressor(max_depth=None)\n",
    "\n",
    "training_sub = np.random.permutation(y.size)[:500]\n",
    "\n",
    "mtree.fit(X.T[training_sub], yall.T[training_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9f61550-f549-4251-9458-ab6774db4910",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = mtree.predict(X.T)\n",
    "\n",
    "fig, axs = plt.subplots(len(svms), 3, figsize=(15, 15))\n",
    "\n",
    "for (ax1, ax2, ax3), (fnm, f), fyp in zip(axs, featuresl.items(), yp.T):\n",
    "    y = featuresl[fnm]\n",
    "\n",
    "    mi = np.min(np.concatenate([y, fyp]))\n",
    "    mx = np.max(np.concatenate([y, fyp]))\n",
    "\n",
    "    sc1 = ax1.scatter(X[0], X[1], c=y, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    sc2 = ax2.scatter(X[0], X[1], c=fyp, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    plt.colorbar(sc1).set_label(fnm)\n",
    "\n",
    "    sc3 = ax3.scatter(X[0], y-fyp, c=X[1], s=2, alpha=.5)\n",
    "    plt.colorbar(sc3).set_label('mag2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21271f0-6c3e-4f0d-b078-1ba124cf60b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd9b60a-a71b-412b-802d-9b9f374084af",
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = ensemble.RandomForestRegressor()\n",
    "\n",
    "training_sub = np.random.permutation(y.size)[:250000]\n",
    "\n",
    "forest.fit(X.T[training_sub], yall.T[training_sub])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497b1552-c956-4f37-a527-021dc9c1501d",
   "metadata": {},
   "outputs": [],
   "source": [
    "yp = forest.predict(X.T)\n",
    "\n",
    "fig, axs = plt.subplots(len(svms), 3, figsize=(15, 15))\n",
    "\n",
    "for (ax1, ax2, ax3), (fnm, f), fyp in zip(axs, featuresl.items(), yp.T):\n",
    "    y = featuresl[fnm]\n",
    "\n",
    "    mi = np.min(np.concatenate([y, fyp]))\n",
    "    mx = np.max(np.concatenate([y, fyp]))\n",
    "\n",
    "    sc1 = ax1.scatter(X[0], X[1], c=y, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    sc2 = ax2.scatter(X[0], X[1], c=fyp, s=2, alpha=.5, vmin=mi, vmax=mx)\n",
    "    plt.colorbar(sc1).set_label(fnm)\n",
    "\n",
    "    sc3 = ax3.scatter(X[0], y-fyp, c=X[1], s=2, alpha=.5)\n",
    "    plt.colorbar(sc3).set_label('mag2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25b5fdfe-0f3b-49bd-8e00-5b7aecc467b0",
   "metadata": {},
   "source": [
    "Kinda works but still really fails to handle metalicity well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f070ab-3c73-4a9f-b7a5-c7221bf10720",
   "metadata": {},
   "source": [
    "# GPyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a905cad7-edf9-48b7-88f9-84d0d7642d6b",
   "metadata": {},
   "source": [
    "First follow the basic tutorial at https://tinygp.readthedocs.io/en/stable/tutorials/intro.html to try to fit just one of the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32603742-b057-48dd-9aaa-99dae38fabcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch_device = (\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")\n",
    "print(f\"Using {torch_device} device\")\n",
    "\n",
    "import gpytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6307e069-dc14-492b-880e-b59c243fec98",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.from_numpy(np.array(list(test_absmags.values()))).T.to(torch_device, dtype=torch.float32)\n",
    "y0_raw = torch.from_numpy(featuresl['logg']).to(torch_device, dtype=torch.float32)\n",
    "\n",
    "y0offset = y0_raw.min()\n",
    "y0scale = y0_raw.max() - y0offset\n",
    "y0 = (y0_raw - y0offset)/y0scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "369da158-e67a-4f75-9eec-da421683df35",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:, 0].cpu(), X[:, 1].cpu(), c=y0.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2586f1d6-7d25-4ad5-98e8-8b77bec367e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExactGPModel(gpytorch.models.ExactGP):\n",
    "    def __init__(self, train_x, train_y, likelihood):\n",
    "        super(ExactGPModel, self).__init__(train_x, train_y, likelihood)\n",
    "        self.mean_module = gpytorch.means.ConstantMean()\n",
    "        self.covar_module = gpytorch.kernels.ScaleKernel(gpytorch.kernels.RBFKernel(ard_num_dims=train_x.shape[-1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean_x = self.mean_module(x)\n",
    "        covar_x = self.covar_module(x)\n",
    "        return gpytorch.distributions.MultivariateNormal(mean_x, covar_x)\n",
    "\n",
    "    def train(self, *args, **kwargs):\n",
    "        super().train(*args, **kwargs)\n",
    "        self.likelihood.train(*args, **kwargs)\n",
    "\n",
    "    def eval(self, *args, **kwargs):\n",
    "        super().eval(*args, **kwargs)\n",
    "        self.likelihood.eval(*args, **kwargs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650d3b9a-9c76-499d-a49b-b616dc738feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(torch_device)\n",
    "model = ExactGPModel(X, y0, likelihood).to(torch_device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model).to(torch_device)\n",
    "\n",
    "\n",
    "fits = []\n",
    "t = tqdm(range(100))\n",
    "for i in t:\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(X)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y0)\n",
    "    loss.backward()\n",
    "    \n",
    "    fits.append([loss.item(), model.likelihood.noise.item()])\n",
    "    for ls in model.covar_module.base_kernel.lengthscale.cpu().detach().numpy()[0]:\n",
    "        fits[-1].append(ls)\n",
    "\n",
    "    t.set_description(f'loss={loss}')\n",
    "    t.refresh()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "labels = ['loss', 'noise']\n",
    "labels.extend([f'lengthscale{i}' for i in range(len(fits[0])-2)])\n",
    "plt.plot(fits, 'o', label=labels)\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72e6560-706a-451f-8af7-ab1d83d32afc",
   "metadata": {},
   "source": [
    "Why does it go crazy at the end?? Well, lets limit to something that's less weird."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817efd3-b68a-4ada-bd18-ef2eac425304",
   "metadata": {},
   "outputs": [],
   "source": [
    "likelihood = gpytorch.likelihoods.GaussianLikelihood().to(torch_device)\n",
    "model = ExactGPModel(X, y0, likelihood).to(torch_device)\n",
    "\n",
    "model.train()\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.1) \n",
    "\n",
    "mll = gpytorch.mlls.ExactMarginalLogLikelihood(likelihood, model).to(torch_device)\n",
    "\n",
    "\n",
    "fits = []\n",
    "t = tqdm(range(75))\n",
    "for i in t:\n",
    "    # Zero gradients from previous iteration\n",
    "    optimizer.zero_grad()\n",
    "    # Output from model\n",
    "    output = model(X)\n",
    "    # Calc loss and backprop gradients\n",
    "    loss = -mll(output, y0)\n",
    "    loss.backward()\n",
    "    \n",
    "    fits.append([loss.item(), model.likelihood.noise.item()])\n",
    "    for ls in model.covar_module.base_kernel.lengthscale.cpu().detach().numpy()[0]:\n",
    "        fits[-1].append(ls)\n",
    "\n",
    "    t.set_description(f'loss={loss}')\n",
    "    t.refresh()\n",
    "    \n",
    "    optimizer.step()\n",
    "    \n",
    "labels = ['loss', 'noise']\n",
    "labels.extend([f'lengthscale{i}' for i in range(len(fits[0])-2)])\n",
    "plt.plot(fits, 'o', label=labels)\n",
    "plt.legend(loc=0);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542b1bd9-34b7-490c-af27-76cf1d8a5bae",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad(), gpytorch.settings.fast_pred_var():\n",
    "    observed_pred = likelihood(model(X))\n",
    "    \n",
    "    plt.scatter(X[:, 0].cpu(), X[:, 1].cpu(), c=observed_pred.mean.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fea7b16-9d06-473f-8ecf-68fe18be98d0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bbe487-8873-4a87-bc83-c3dd0d381609",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b7b146-c71e-4589-9e4a-56f38750ce4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35c81021-27ef-4dd9-9340-8e8d1d1614b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
